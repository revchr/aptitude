{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521cd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os.path\n",
    "import urllib.request\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, desc\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampNTZType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c6ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(\"Yellow Taxi Trip Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775b5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data from the website\n",
    "url = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b1395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use BeautifulSoup for data scraping\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1132f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the links to download each parquet file\n",
    "urls = []\n",
    "\n",
    "#We have data from 2009-2023. This means there are 15 years of data for each month of the year \n",
    "for i in range(15):\n",
    "    table_year = soup.find_all('table')[i] #find the table that is related to the year data\n",
    "\n",
    "    yt = table_year.find_all('a',{\"title\":\"Yellow Taxi Trip Records\"}) #find the data related to Yellow Taxi Trip Records\n",
    "\n",
    "    for month in range(len(yt)):\n",
    "        #Get the link for each month of the year and add it to the urls list\n",
    "        urls.append(table_year.find_all('a',{\"title\":\"Yellow Taxi Trip Records\"})[month].get(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e802add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if all links of data files are there 14years(from 2009-2022)*12months + 7months (2023) = 175\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2758e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a path for each data file \n",
    "filename_list = [] #all the name files will be added into that list\n",
    "for url in urls:\n",
    "    #cut the name of the url to get only the information about the date of the file\n",
    "    test_name = url.rsplit('/', 1)[-1]\n",
    "    final_name = test_name.split('.')[0]\n",
    "    filename_list.append(final_name)\n",
    "\n",
    "    filename = os.path.join('Yellow Taxi Trip Data', final_name) #create the filename path for each data file\n",
    "\n",
    "    # Download the file if it does not exist\n",
    "    if not os.path.isfile(filename):\n",
    "        print('Downloading: ' + filename)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "            print('Encountered unknown error. Continuing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d2a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/23 09:40:30 WARN Utils: Your hostname, Reveccas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.10 instead (on interface en0)\n",
      "23/10/23 09:40:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/23 09:40:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/23 09:40:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder.appName('YellowTaxiTripData').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d86818bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load into the dataframe the parquet file of July 2023\n",
    "parquet_file_path = '/Users/reveccachristou/Desktop/Aptitude/Yellow Taxi Trip Data/yellow_tripdata_2023-01'\n",
    "df1 = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef0968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3066766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>27.02038310708492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>22.163588952492184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>1169.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        total_amount\n",
       "0   count             3066766\n",
       "1    mean   27.02038310708492\n",
       "2  stddev  22.163588952492184\n",
       "3     min              -751.0\n",
       "4     max              1169.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.select(\"total_amount\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "280f68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:============================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2023-01-24 12:43:44|  2023-01-24 15:41:02|            1.0|       177.88|       4.0|                 N|         132|         265|           2|     1160.1|  0.0|    0.5|       0.0|        6.55|                  1.0|      1169.4|                 0.0|       1.25|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the record that has the maximum total amount value to check for outliers\n",
    "filtered_df = df1.filter(df1['total_amount'] == 1169.4)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4051e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25204"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many negative-value records exist in the total_amount field\n",
    "negative_amount_values_count = df1.filter(df1[\"total_amount\"] < 0).count()\n",
    "negative_amount_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ab0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2023-01-01 00:28:29|  2023-01-01 00:31:03|            1.0|         0.42|       1.0|                 N|         233|         229|           4|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:20:18|  2023-01-01 00:27:56|            2.0|         1.19|       1.0|                 N|         142|          50|           4|       -9.3| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -14.3|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:52:22|  2023-01-01 01:14:03|            1.0|         4.89|       1.0|                 N|         238|         167|           4|      -25.4| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -30.4|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:06:39|  2023-01-01 00:10:02|            1.0|         0.52|       1.0|                 N|         237|         237|           2|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:34:39|  2023-01-01 00:40:25|            2.0|         0.85|       1.0|                 N|          79|         113|           4|       -7.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -12.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:26:51|  2023-01-01 00:26:56|            1.0|         0.04|       1.0|                 N|         114|         114|           3|       -3.0| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        -5.5|                 0.0|        0.0|\n",
      "|       2| 2023-01-01 00:02:59|  2023-01-01 00:08:01|            2.0|         0.68|       1.0|                 N|         234|         164|           4|       -7.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -12.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:40:02|  2023-01-01 01:07:56|            1.0|          9.9|       1.0|                 N|          90|          67|           4|      -43.6| -1.0|   -0.5|       0.0|       -6.55|                 -1.0|      -55.15|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:25:04|  2023-01-01 00:43:27|            2.0|         2.41|       1.0|                 N|          50|         229|           4|      -15.6| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -20.6|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:50:09|  2023-01-01 00:50:13|            1.0|          0.0|       1.0|                 N|         163|         163|           4|       -3.0| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        -8.0|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:28:30|  2023-01-01 00:32:16|            1.0|          0.0|       1.0|                 N|         161|         161|           4|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:10:57|  2023-01-01 00:18:31|            2.0|         0.84|       1.0|                 N|         164|         233|           2|       -8.6| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -13.6|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:33:21|  2023-01-01 00:47:59|            3.0|         8.17|       4.0|                 N|         132|         265|           4|      -39.4| -1.0|   -0.5|       0.0|         0.0|                 -1.0|      -43.15|                 0.0|      -1.25|\n",
      "|       2| 2023-01-01 00:13:33|  2023-01-01 00:38:08|            2.0|        11.91|       1.0|                 N|         132|           9|           4|      -45.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|      -49.45|                 0.0|      -1.25|\n",
      "|       2| 2023-01-01 00:30:41|  2023-01-01 00:45:57|            1.0|         6.81|       1.0|                 N|         162|          13|           3|      -28.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -33.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:36:44|  2023-01-01 00:43:05|            1.0|         0.25|       1.0|                 N|         162|         162|           2|       -3.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        -8.7|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:56:41|  2023-01-01 01:07:44|            1.0|         2.09|       1.0|                 N|         143|         236|           4|      -13.5| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -18.5|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:34:51|  2023-01-01 00:45:41|            1.0|          3.4|       1.0|                 N|          79|          87|           4|      -17.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -22.7|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:58:43|  2023-01-01 01:40:36|            2.0|        12.82|       1.0|                 N|          68|         228|           4|      -55.5| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -60.5|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:09:55|  2023-01-01 00:18:05|            1.0|         1.12|       1.0|                 N|         161|         170|           4|       -9.3| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -14.3|                -2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "negative_amount_values = df1.filter(df1[\"total_amount\"] < 0)# .count()\n",
    "negative_amount_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd02b322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2023-01-01 00:28:29|  2023-01-01 00:31:03|            1.0|         0.42|       1.0|                 N|         233|         229|           4|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:20:18|  2023-01-01 00:27:56|            2.0|         1.19|       1.0|                 N|         142|          50|           4|       -9.3| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        14.3|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:52:22|  2023-01-01 01:14:03|            1.0|         4.89|       1.0|                 N|         238|         167|           4|      -25.4| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        30.4|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:06:39|  2023-01-01 00:10:02|            1.0|         0.52|       1.0|                 N|         237|         237|           2|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:34:39|  2023-01-01 00:40:25|            2.0|         0.85|       1.0|                 N|          79|         113|           4|       -7.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        12.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:26:51|  2023-01-01 00:26:56|            1.0|         0.04|       1.0|                 N|         114|         114|           3|       -3.0| -1.0|   -0.5|       0.0|         0.0|                 -1.0|         5.5|                 0.0|        0.0|\n",
      "|       2| 2023-01-01 00:02:59|  2023-01-01 00:08:01|            2.0|         0.68|       1.0|                 N|         234|         164|           4|       -7.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        12.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:40:02|  2023-01-01 01:07:56|            1.0|          9.9|       1.0|                 N|          90|          67|           4|      -43.6| -1.0|   -0.5|       0.0|       -6.55|                 -1.0|       55.15|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:25:04|  2023-01-01 00:43:27|            2.0|         2.41|       1.0|                 N|          50|         229|           4|      -15.6| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        20.6|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:50:09|  2023-01-01 00:50:13|            1.0|          0.0|       1.0|                 N|         163|         163|           4|       -3.0| -1.0|   -0.5|       0.0|         0.0|                 -1.0|         8.0|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:28:30|  2023-01-01 00:32:16|            1.0|          0.0|       1.0|                 N|         161|         161|           4|       -5.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        10.1|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:10:57|  2023-01-01 00:18:31|            2.0|         0.84|       1.0|                 N|         164|         233|           2|       -8.6| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        13.6|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:33:21|  2023-01-01 00:47:59|            3.0|         8.17|       4.0|                 N|         132|         265|           4|      -39.4| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       43.15|                 0.0|      -1.25|\n",
      "|       2| 2023-01-01 00:13:33|  2023-01-01 00:38:08|            2.0|        11.91|       1.0|                 N|         132|           9|           4|      -45.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       49.45|                 0.0|      -1.25|\n",
      "|       2| 2023-01-01 00:30:41|  2023-01-01 00:45:57|            1.0|         6.81|       1.0|                 N|         162|          13|           3|      -28.2| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        33.2|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:36:44|  2023-01-01 00:43:05|            1.0|         0.25|       1.0|                 N|         162|         162|           2|       -3.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|         8.7|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:56:41|  2023-01-01 01:07:44|            1.0|         2.09|       1.0|                 N|         143|         236|           4|      -13.5| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        18.5|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:34:51|  2023-01-01 00:45:41|            1.0|          3.4|       1.0|                 N|          79|          87|           4|      -17.7| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        22.7|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:58:43|  2023-01-01 01:40:36|            2.0|        12.82|       1.0|                 N|          68|         228|           4|      -55.5| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        60.5|                -2.5|        0.0|\n",
      "|       2| 2023-01-01 00:09:55|  2023-01-01 00:18:05|            1.0|         1.12|       1.0|                 N|         161|         170|           4|       -9.3| -1.0|   -0.5|       0.0|         0.0|                 -1.0|        14.3|                -2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change the negative values to positive since this might be a wrong input\n",
    "from pyspark.sql.functions import abs\n",
    "df_with_positive = negative_amount_values.withColumn('total_amount', abs(negative_amount_values['total_amount']))\n",
    "df_with_positive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269c43b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are any null values. In this case, there are none.\n",
    "df1.filter(df1.total_amount.isNull()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef7ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
